{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506652e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Notebook 3 (v2): Otimização, SHAP e Interpretação\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Configuração e Carregamento de Bibliotecas e Dados\n",
    "# ------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import shap # <-- Importação da biblioteca SHAP\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV # <-- Importação para otimização\n",
    "from sklearn.ensemble import RandomForestClassifier # <-- Importação do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b338585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definindo os caminhos conforme a estrutura de diretórios ---\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "PROCESSED_SPLIT_PATH = os.path.join(ROOT_DIR, 'data', 'processed', 'split')\n",
    "FINAL_MODEL_PATH = os.path.join(ROOT_DIR, 'models', 'final_model_v2') # <-- Novo diretório para a v2\n",
    "REPORTS_PATH = os.path.join(ROOT_DIR, 'reports', 'v2') # <-- Novo diretório para relatórios da v2\n",
    "PLOTS_PATH = os.path.join(ROOT_DIR, 'reports', 'v2', 'plots') # <-- Novo diretório para gráficos da v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91a3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os diretórios se não existirem\n",
    "os.makedirs(FINAL_MODEL_PATH, exist_ok=True)\n",
    "os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "os.makedirs(PLOTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad1a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando conjuntos de treino e teste salvos...\n",
      "✅ Dados de treino e teste carregados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Carregando os conjuntos de treino e teste salvos no Notebook 2\n",
    "print(\"Carregando conjuntos de treino e teste salvos...\")\n",
    "try:\n",
    "    X_train = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'X_train.csv'))\n",
    "    X_test = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'X_test.csv'))\n",
    "    y_train = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'y_train.csv')).squeeze()\n",
    "    y_test = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'y_test.csv')).squeeze()\n",
    "    print(\"✅ Dados de treino e teste carregados com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Erro: Arquivos de split não encontrados. Certifique-se de ter executado o Notebook 2.\")\n",
    "    X_train, X_test, y_train, y_test = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63d7c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tratando o desbalanceamento de classes com SMOTE...\n",
      "✅ SMOTE aplicado. Dimensão do conjunto de treino após SMOTE:\n",
      "X_train_res: (7228, 30) | y_train_res: (7228,)\n"
     ]
    }
   ],
   "source": [
    "if X_train is not None:\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 2. Tratamento de Classes Desbalanceadas (SMOTE)\n",
    "    # ------------------------------------------------------------------------------\n",
    "    print(\"\\nTratando o desbalanceamento de classes com SMOTE...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    print(\"✅ SMOTE aplicado. Dimensão do conjunto de treino após SMOTE:\")\n",
    "    print(f\"X_train_res: {X_train_res.shape} | y_train_res: {y_train_res.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45ed8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando a otimização de hiperparâmetros com Randomized Search...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "✅ Otimização concluída.\n",
      "Melhores hiperparâmetros encontrados: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 3. Otimização de Hiperparâmetros (Randomized Search)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nIniciando a otimização de hiperparâmetros com Randomized Search...\")\n",
    "    \n",
    "# Modelo base para a otimização\n",
    "model_base = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Parâmetros para Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, \n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "    \n",
    "random_search.fit(X_train_res, y_train_res)\n",
    "best_model_tuned = random_search.best_estimator_\n",
    "\n",
    "print(\"\\n✅ Otimização concluída.\")\n",
    "print(f\"Melhores hiperparâmetros encontrados: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b01ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Avaliação Final do Modelo Otimizado ---\n",
      "✅ Métricas do modelo final v2 salvas em 'final_model_metrics_v2.json'.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 4. Avaliação e Interpretação do Modelo Otimizado\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Avaliação Final do Modelo Otimizado ---\")\n",
    "    \n",
    "y_pred_proba = best_model_tuned.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "# Otimização do limiar\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "f1_scores = [f1_score(y_test, y_pred_proba > t, zero_division=0) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_optimized = (y_pred_proba >= best_threshold).astype(int)\n",
    "    \n",
    "# Gerando métricas de forma estruturada para JSON\n",
    "report_dict = classification_report(y_test, y_pred_optimized, output_dict=True)\n",
    "final_metrics = {\n",
    "    'accuracy': report_dict['accuracy'],\n",
    "    'precision': report_dict['macro avg']['precision'],\n",
    "    'recall': report_dict['macro avg']['recall'],\n",
    "    'f1-score': report_dict['macro avg']['f1-score'],\n",
    "    'auc_score': roc_auc_score(y_test, y_pred_proba),\n",
    "    'best_threshold': best_threshold,\n",
    "    'best_params': random_search.best_params_\n",
    "}\n",
    "    \n",
    "with open(os.path.join(REPORTS_PATH, 'final_model_metrics_v2.json'), 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=4)\n",
    "print(\"✅ Métricas do modelo final v2 salvas em 'final_model_metrics_v2.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f78d22fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Interpretação do Modelo com SHAP ---\n",
      "\n",
      "=== VERIFICAÇÃO DE COMPATIBILIDADE ===\n",
      "Número de features no modelo: 30\n",
      "Número de features em X_test: 30\n",
      "✅ Compatibilidade de features confirmada\n",
      "\n",
      "=== PROCESSAMENTO DOS SHAP VALUES ===\n",
      "Detectado modelo binário (formato 3D)\n",
      "Shape final dos SHAP values: (2110, 30)\n",
      "\n",
      "Gerando gráfico SHAP...\n",
      "✅ Gráfico SHAP salvo em: c:\\temp\\Telecom_X_PrevendoChurn\\reports\\v2\\plots\\shap_summary_plot_v2.png\n",
      "✅ Explainer SHAP salvo em: c:\\temp\\Telecom_X_PrevendoChurn\\models\\final_model_v2\\shap_explainer_v2.pkl\n",
      "✅ Modelo final salvo em: c:\\temp\\Telecom_X_PrevendoChurn\\models\\final_model_v2\\random_forest_final_v2.pkl\n",
      "\n",
      "✅ Processo do Notebook 3 concluído com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 5. Interpretação do Modelo com SHAP (Versão Robustecida)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Interpretação do Modelo com SHAP ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Criação do Explainer com verificação\n",
    "    explainer = shap.TreeExplainer(best_model_tuned)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "    # Verificação de compatibilidade\n",
    "    print(\"\\n=== VERIFICAÇÃO DE COMPATIBILIDADE ===\")\n",
    "    print(f\"Número de features no modelo: {best_model_tuned.n_features_in_}\")\n",
    "    print(f\"Número de features em X_test: {X_test.shape[1]}\")\n",
    "    \n",
    "    assert best_model_tuned.n_features_in_ == X_test.shape[1], \\\n",
    "        f\"ERRO: Modelo foi treinado com {best_model_tuned.n_features_in_} features mas X_test tem {X_test.shape[1]}\"\n",
    "    print(\"✅ Compatibilidade de features confirmada\")\n",
    "    \n",
    "    # 2. Processamento dos SHAP values com detecção automática\n",
    "    print(\"\\n=== PROCESSAMENTO DOS SHAP VALUES ===\")\n",
    "    if isinstance(shap_values, list):\n",
    "        # Modelo multiclasse\n",
    "        print(f\"Detectado modelo multiclasse com {len(shap_values)} classes\")\n",
    "        shap_values_plot = shap_values[1]  # Seleciona classe 1 (ajuste conforme necessidade)\n",
    "    elif len(shap_values.shape) == 3:\n",
    "        # Modelo binário (formato numpy array 3D)\n",
    "        print(\"Detectado modelo binário (formato 3D)\")\n",
    "        shap_values_plot = shap_values[:,:,1]  # Seleciona classe positiva\n",
    "    else:\n",
    "        # Modelo de regressão ou binário (formato 2D)\n",
    "        print(\"Detectado modelo de regressão ou binário (formato 2D)\")\n",
    "        shap_values_plot = shap_values\n",
    "    \n",
    "    print(f\"Shape final dos SHAP values: {shap_values_plot.shape}\")\n",
    "    \n",
    "    # 3. Verificação final de dimensões\n",
    "    if shap_values_plot.shape[1] != X_test.shape[1]:\n",
    "        print(\"Ajustando dimensões...\")\n",
    "        min_features = min(shap_values_plot.shape[1], X_test.shape[1])\n",
    "        shap_values_plot = shap_values_plot[:, :min_features]\n",
    "        X_test_plot = X_test.iloc[:, :min_features]\n",
    "    else:\n",
    "        X_test_plot = X_test\n",
    "    \n",
    "    # 4. Geração do gráfico com tratamento de erros\n",
    "    print(\"\\nGerando gráfico SHAP...\")\n",
    "    shap.summary_plot(\n",
    "        shap_values_plot,\n",
    "        features=X_test_plot,\n",
    "        feature_names=X_test_plot.columns.tolist(),\n",
    "        show=False\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(PLOTS_PATH, 'shap_summary_plot_v2.png')\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"✅ Gráfico SHAP salvo em: {plot_path}\")\n",
    "    \n",
    "    # 5. Salvamento dos artefatos\n",
    "    explainer_path = os.path.join(FINAL_MODEL_PATH, 'shap_explainer_v2.pkl')\n",
    "    joblib.dump(explainer, explainer_path)\n",
    "    print(f\"✅ Explainer SHAP salvo em: {explainer_path}\")\n",
    "    \n",
    "    model_path = os.path.join(FINAL_MODEL_PATH, 'random_forest_final_v2.pkl')\n",
    "    joblib.dump(best_model_tuned, model_path)\n",
    "    print(f\"✅ Modelo final salvo em: {model_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ ERRO NA INTERPRETAÇÃO SHAP: {str(e)}\")\n",
    "    print(\"\\nDIAGNÓSTICO DO ERRO:\")\n",
    "    \n",
    "    if 'shap_values' in locals():\n",
    "        print(f\"\\nTipo dos SHAP values: {type(shap_values)}\")\n",
    "        if hasattr(shap_values, 'shape'):\n",
    "            print(f\"Shape dos SHAP values: {shap_values.shape}\")\n",
    "        elif isinstance(shap_values, list):\n",
    "            print(f\"Número de classes: {len(shap_values)}\")\n",
    "            for i, sv in enumerate(shap_values):\n",
    "                print(f\"Classe {i} shape: {sv.shape}\")\n",
    "    \n",
    "    print(\"\\nSUGESTÕES PARA CORREÇÃO:\")\n",
    "    print(\"1. Verifique se todas as colunas de X_test são numéricas\")\n",
    "    print(\"2. Confira o pré-processamento dos dados de teste\")\n",
    "    print(\"3. Experimente usar X_test.values em vez do DataFrame\")\n",
    "    print(\"4. Para modelos binários, use shap_values[:,:,0] ou shap_values[:,:,1]\")\n",
    "    \n",
    "    raise  # Remove esta linha se não quiser interromper a execução\n",
    "\n",
    "print(\"\\n✅ Processo do Notebook 3 concluído com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
