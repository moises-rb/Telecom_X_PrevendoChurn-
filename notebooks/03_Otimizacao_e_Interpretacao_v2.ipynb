{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "506652e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Notebook 3 (v2): Otimização, SHAP e Interpretação\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Configuração e Carregamento de Bibliotecas e Dados\n",
    "# ------------------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import shap # <-- Importação da biblioteca SHAP\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV # <-- Importação para otimização\n",
    "from sklearn.ensemble import RandomForestClassifier # <-- Importação do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b338585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Definindo os caminhos conforme a estrutura de diretórios ---\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "PROCESSED_SPLIT_PATH = os.path.join(ROOT_DIR, 'data', 'processed', 'split')\n",
    "FINAL_MODEL_PATH = os.path.join(ROOT_DIR, 'models', 'final_model_v2') # <-- Novo diretório para a v2\n",
    "REPORTS_PATH = os.path.join(ROOT_DIR, 'reports', 'v2') # <-- Novo diretório para relatórios da v2\n",
    "PLOTS_PATH = os.path.join(ROOT_DIR, 'reports', 'v2', 'plots') # <-- Novo diretório para gráficos da v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b91a3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os diretórios se não existirem\n",
    "os.makedirs(FINAL_MODEL_PATH, exist_ok=True)\n",
    "os.makedirs(REPORTS_PATH, exist_ok=True)\n",
    "os.makedirs(PLOTS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad1a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando conjuntos de treino e teste salvos...\n",
      "✅ Dados de treino e teste carregados com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Carregando os conjuntos de treino e teste salvos no Notebook 2\n",
    "print(\"Carregando conjuntos de treino e teste salvos...\")\n",
    "try:\n",
    "    X_train = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'X_train.csv'))\n",
    "    X_test = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'X_test.csv'))\n",
    "    y_train = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'y_train.csv')).squeeze()\n",
    "    y_test = pd.read_csv(os.path.join(PROCESSED_SPLIT_PATH, 'y_test.csv')).squeeze()\n",
    "    print(\"✅ Dados de treino e teste carregados com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Erro: Arquivos de split não encontrados. Certifique-se de ter executado o Notebook 2.\")\n",
    "    X_train, X_test, y_train, y_test = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e63d7c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tratando o desbalanceamento de classes com SMOTE...\n",
      "✅ SMOTE aplicado. Dimensão do conjunto de treino após SMOTE:\n",
      "X_train_res: (7228, 30) | y_train_res: (7228,)\n"
     ]
    }
   ],
   "source": [
    "if X_train is not None:\n",
    "    # ------------------------------------------------------------------------------\n",
    "    # 2. Tratamento de Classes Desbalanceadas (SMOTE)\n",
    "    # ------------------------------------------------------------------------------\n",
    "    print(\"\\nTratando o desbalanceamento de classes com SMOTE...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    print(\"✅ SMOTE aplicado. Dimensão do conjunto de treino após SMOTE:\")\n",
    "    print(f\"X_train_res: {X_train_res.shape} | y_train_res: {y_train_res.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b45ed8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando a otimização de hiperparâmetros com Randomized Search...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "\n",
      "✅ Otimização concluída.\n",
      "Melhores hiperparâmetros encontrados: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 3. Otimização de Hiperparâmetros (Randomized Search)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\nIniciando a otimização de hiperparâmetros com Randomized Search...\")\n",
    "    \n",
    "# Modelo base para a otimização\n",
    "model_base = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Parâmetros para Randomized Search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, \n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "    \n",
    "random_search.fit(X_train_res, y_train_res)\n",
    "best_model_tuned = random_search.best_estimator_\n",
    "\n",
    "print(\"\\n✅ Otimização concluída.\")\n",
    "print(f\"Melhores hiperparâmetros encontrados: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0b01ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Avaliação Final do Modelo Otimizado ---\n",
      "✅ Métricas do modelo final v2 salvas em 'final_model_metrics_v2.json'.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 4. Avaliação e Interpretação do Modelo Otimizado\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Avaliação Final do Modelo Otimizado ---\")\n",
    "    \n",
    "y_pred_proba = best_model_tuned.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "# Otimização do limiar\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "f1_scores = [f1_score(y_test, y_pred_proba > t, zero_division=0) for t in thresholds]\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_optimized = (y_pred_proba >= best_threshold).astype(int)\n",
    "    \n",
    "# Gerando métricas de forma estruturada para JSON\n",
    "report_dict = classification_report(y_test, y_pred_optimized, output_dict=True)\n",
    "final_metrics = {\n",
    "    'accuracy': report_dict['accuracy'],\n",
    "    'precision': report_dict['macro avg']['precision'],\n",
    "    'recall': report_dict['macro avg']['recall'],\n",
    "    'f1-score': report_dict['macro avg']['f1-score'],\n",
    "    'auc_score': roc_auc_score(y_test, y_pred_proba),\n",
    "    'best_threshold': best_threshold,\n",
    "    'best_params': random_search.best_params_\n",
    "}\n",
    "    \n",
    "with open(os.path.join(REPORTS_PATH, 'final_model_metrics_v2.json'), 'w') as f:\n",
    "    json.dump(final_metrics, f, indent=4)\n",
    "print(\"✅ Métricas do modelo final v2 salvas em 'final_model_metrics_v2.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3e33da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Interpretação do Modelo com SHAP ---\n",
      "✅ Explainer SHAP salvo com sucesso.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Explainer SHAP salvo com sucesso.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Usando shap_values[1] para a classe de interesse\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PLOTS_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshap_summary_plot_v2.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\shap\\plots\\_beeswarm.py:664\u001b[0m, in \u001b[0;36msummary_legacy\u001b[1;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale, rng)\u001b[0m\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    660\u001b[0m             shape_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    661\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    662\u001b[0m         )\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 664\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m num_features \u001b[38;5;241m==\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], shape_msg\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labels[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEATURE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[1;31mAssertionError\u001b[0m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# 5. Interpretação do Modelo com SHAP\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- Interpretação do Modelo com SHAP ---\")\n",
    "\n",
    "# Criando o explainer SHAP\n",
    "explainer = shap.TreeExplainer(best_model_tuned)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "# Salvando o explainer para uso futuro\n",
    "joblib.dump(explainer, os.path.join(FINAL_MODEL_PATH, 'shap_explainer_v2.pkl'))\n",
    "print(\"✅ Explainer SHAP salvo com sucesso.\")\n",
    "\n",
    "# Usando shap_values[1] para a classe de interesse\n",
    "shap.summary_plot(shap_values[1], features=X_test, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(PLOTS_PATH, 'shap_summary_plot_v2.png'))\n",
    "plt.close() # <-- Fechar o plot para não exibir no notebook\n",
    "print(\"✅ Gráfico de resumo SHAP salvo em 'shap_summary_plot_v2.png'.\")\n",
    "    \n",
    "# Salvando o modelo final otimizado\n",
    "joblib.dump(best_model_tuned, os.path.join(FINAL_MODEL_PATH, 'random_forest_final_v2.pkl'))\n",
    "print(\"✅ Modelo final otimizado v2 salvo com sucesso.\")\n",
    "    \n",
    "print(\"\\nProcesso do Notebook 3 (v2) concluído com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
